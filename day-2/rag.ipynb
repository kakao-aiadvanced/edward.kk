{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX-gGpMFBskB"
      },
      "source": [
        "오늘 만들 RAG + Chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdnZG9gjA5ST"
      },
      "source": [
        "![](https://github.com/user-attachments/assets/7e132d65-c077-4686-981d-ac645b5e90f6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k71_Jmn4vOgc"
      },
      "source": [
        "프레임워크\n",
        "- Langchain\n",
        "- 비슷한 역할을 하는 Llamaindex 등이 있는데, 학습 단계에서는 이들이 유용하지만, 실제 서빙을 위한 서비스를 개발하다 보면 하나 둘 직접 구현하게 되는 경우가 많음.\n",
        "\n",
        "모델\n",
        "- gpt-4o-mini\n",
        "- Langchain ChatOllama 를 활용하면 Langchain 위에 첫날 실습한 Ollama + Local model 을 활용해서 구현할 수 있음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GsYlNbK-sW28"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install langchain langchain-openai langchain-openai langchain_chroma langchain-text-splitters langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCfkGs8hqwAI",
        "outputId": "d7df36ee-8d65-40ef-b409-67133288a7ce"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6QlQjnMqoOA"
      },
      "source": [
        "**기본 RAG tutorial**\n",
        "\n",
        "https://python.langchain.com/v0.2/docs/tutorials/rag/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIY9YKZY4Pfn",
        "outputId": "a99d146a-6a05-4878-9b23-39bc558710c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/edward.kk/.pyenv/versions/3.11.9/lib/python3.11/site-packages/langsmith/client.py:333: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: filler question \\nContext: filler context \\nAnswer:\")]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain import hub\n",
        "\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "example_messages = prompt.invoke(\n",
        "    {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
        ").to_messages()\n",
        "\n",
        "example_messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPEI19iX4Ma8"
      },
      "source": [
        "output JSON formatting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "19G-Gs8Pvz-p",
        "outputId": "94b0f89d-232a-43a3-bc35-8df65f232756"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/edward.kk/.pyenv/versions/3.11.9/lib/python3.11/site-packages/langsmith/client.py:333: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Task decomposition is the process of breaking down complex tasks into smaller, manageable steps to facilitate execution. Techniques like Chain of Thought (CoT) and Tree of Thoughts enhance this process by allowing models to \"think step by step\" and explore multiple reasoning possibilities. This can be achieved through simple prompting, task-specific instructions, or human inputs.'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Load, chunk and index the contents of the blog.\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
        "\n",
        "# Retrieve and generate using the relevant snippets of the blog.\n",
        "retriever = vectorstore.as_retriever()\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "rag_chain.invoke(\"What is Task Decomposition?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2GWl82ovu6v"
      },
      "source": [
        "**1. 3개의 블로그 포스팅 본문을 Load: WebBaseLoader 활용**\n",
        "\n",
        "https://python.langchain.com/v0.2/docs/integrations/document_loaders/web_base/[link text](https://)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MbuUZ2rqwn45"
      },
      "outputs": [],
      "source": [
        "urls = [\n",
        "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "loader = WebBaseLoader(\n",
        "    web_paths=urls,\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POwtiasPq4gH"
      },
      "source": [
        "**2. 불러온 본문을 Split (Chunking) : recursive text splitter 활용**\n",
        "\n",
        "https://python.langchain.com/v0.2/docs/how_to/recursive_text_splitter/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "총 3개의 문서를 불러왔습니다.\n",
            "분할 후 총 183개의 청크가 생성되었습니다.\n",
            "\n",
            "첫 번째 청크의 일부:\n",
            "LLM Powered Autonomous Agents\n",
            "    \n",
            "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
            "\n",
            "\n",
            "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring...\n"
          ]
        }
      ],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "print(f\"총 {len(docs)}개의 문서를 불러왔습니다.\")\n",
        "print(f\"분할 후 총 {len(splits)}개의 청크가 생성되었습니다.\")\n",
        "\n",
        "# 첫 번째 청크의 내용 일부 출력 (예시)\n",
        "if splits:\n",
        "    print(\"\\n첫 번째 청크의 일부:\")\n",
        "    print(splits[0].page_content[:300] + \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srlRewINq40y"
      },
      "source": [
        "**3. Chunks 를 임베딩하여 Vector store 저장: openai, chroma 사용**\n",
        "\n",
        "embedding model 은 \"text-embedding-3-small\" 사용\n",
        "\n",
        "embedding: https://python.langchain.com/v0.2/docs/integrations/text_embedding/openai/\n",
        "\n",
        "vetor store: https://python.langchain.com/v0.2/docs/integrations/vectorstores/chroma/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/vf/ln_hnh193wq4mx834q88jswh0000gn/T/ipykernel_92246/3089316810.py:15: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  vectorstore.persist()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "벡터 스토어가 생성되었습니다. 총 183 개의 벡터가 저장되었습니다.\n",
            "\n",
            "쿼리 'What are AI agents?'에 대한 top 2 결과:\n",
            "\n",
            "1. Fig. 13. The generative agent architecture. (Image source: Park et al. 2023)\n",
            "This fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agent...\n",
            "\n",
            "2. LLM Powered Autonomous Agents\n",
            "    \n",
            "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
            "\n",
            "\n",
            "Building agents with LLM (large language model) as its core controller is a cool con...\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "# OpenAI 임베딩 모델 초기화\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "# Chroma 벡터 스토어 생성\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=splits,  # 이전 단계에서 생성한 splits 사용\n",
        "    embedding=embeddings,\n",
        "    persist_directory=\"./chroma_db\"  # 벡터 스토어를 로컬에 저장할 디렉토리\n",
        ")\n",
        "\n",
        "# 벡터 스토어 저장\n",
        "vectorstore.persist()\n",
        "\n",
        "print(f\"벡터 스토어가 생성되었습니다. 총 {vectorstore._collection.count()} 개의 벡터가 저장되었습니다.\")\n",
        "\n",
        "# 간단한 검색 예시\n",
        "query = \"What are AI agents?\"\n",
        "results = vectorstore.similarity_search(query, k=2)\n",
        "\n",
        "print(f\"\\n쿼리 '{query}'에 대한 top 2 결과:\")\n",
        "for i, doc in enumerate(results, 1):\n",
        "    print(f\"\\n{i}. {doc.page_content[:200]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f80hfgluq43Q"
      },
      "source": [
        "**4. User query = ‘agent memory’ 를 받아 관련된 chunks를 retrieve**\n",
        "\n",
        "https://python.langchain.com/v0.2/docs/how_to/vectorstore_retriever/\n",
        "\n",
        "https://api.python.langchain.com/en/latest/vectorstores/langchain_core.vectorstores.VectorStore.html#langchain_core.vectorstores.VectorStore.as_retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "uTecpoVqyt3-",
        "outputId": "ea9ef118-2d11-4d0b-c400-caf89fefe62d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "쿼리 'agent memory'에 대한 검색 결과:\n",
            "\n",
            "1. 내용: Memory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\n",
            "\n",
            "Each element is an observation, an event directly provided...\n",
            "   메타데이터: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "\n",
            "2. 내용: LLM Powered Autonomous Agents\n",
            "    \n",
            "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
            "\n",
            "\n",
            "Building agents with LLM (large language model) as its core controller is a cool con...\n",
            "   메타데이터: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "\n",
            "3. 내용: Memory\n",
            "\n",
            "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\n",
            "Long-term memory: This provides the agent with th...\n",
            "   메타데이터: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
            "\n",
            "총 3개의 관련 문서를 검색했습니다.\n",
            "\n",
            "유사도 점수:\n",
            "1. 점수: 1.2622\n",
            "2. 점수: 1.2750\n",
            "3. 점수: 1.2816\n"
          ]
        }
      ],
      "source": [
        "from langchain.schema import Document\n",
        "\n",
        "# 이전에 생성한 vectorstore를 사용합니다\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "# 사용자 쿼리 설정\n",
        "user_query = \"agent memory\"\n",
        "\n",
        "# 쿼리 실행\n",
        "retrieved_docs = retriever.invoke(user_query)\n",
        "\n",
        "print(f\"쿼리 '{user_query}'에 대한 검색 결과:\")\n",
        "for i, doc in enumerate(retrieved_docs, 1):\n",
        "    if isinstance(doc, Document):\n",
        "        print(f\"\\n{i}. 내용: {doc.page_content[:200]}...\")\n",
        "        print(f\"   메타데이터: {doc.metadata}\")\n",
        "    else:\n",
        "        print(f\"\\n{i}. {doc[:200]}...\")  # Document 객체가 아닌 경우\n",
        "\n",
        "# 검색된 문서의 총 수 출력\n",
        "print(f\"\\n총 {len(retrieved_docs)}개의 관련 문서를 검색했습니다.\")\n",
        "\n",
        "# 선택적: 임베딩 벡터 유사도 점수 확인 (Chroma에서 지원하는 경우)\n",
        "if hasattr(vectorstore, 'similarity_search_with_score'):\n",
        "    docs_and_scores = vectorstore.similarity_search_with_score(user_query, k=3)\n",
        "    print(\"\\n유사도 점수:\")\n",
        "    for i, (doc, score) in enumerate(docs_and_scores, 1):\n",
        "        print(f\"{i}. 점수: {score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "5FiAUX0P0RA_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## 1. MMR 검색 결과 (다양성 증가):\n",
            "1. Memory stream: is a long-term memory module (external database) that records a comprehensive list of...\n",
            "2. Fig. 13. The generative agent architecture. (Image source: Park et al. 2023)\n",
            "This fun simulation res...\n",
            "3. }\n",
            "]\n",
            "Then after these clarification, the agent moved into the code writing mode with a different syst...\n",
            "4. Maximum Inner Product Search (MIPS)#\n",
            "The external memory can alleviate the restriction of finite att...\n",
            "5. Prefix Injection: Ask the model to start with an affirmative confirmation.\n",
            "Refusal suppression: Give...\n",
            "6. This benchmark evaluates the agent’s tool use capabilities at three levels:\n",
            "\n",
            "Level-1 evaluates the a...\n",
            "\n",
            "## 2. MMR 검색 결과 (높은 fetch_k):\n",
            "1. Memory stream: is a long-term memory module (external database) that records a comprehensive list of...\n",
            "2. }\n",
            "]\n",
            "Then after these clarification, the agent moved into the code writing mode with a different syst...\n",
            "3. One simple and intuitive way to defend the model against adversarial attacks is to explicitly instru...\n",
            "4. $$\n",
            "\\text{max}_{(\\mathbf{x}, \\mathbf{y}) \\in \\mathcal{X} \\times \\mathcal{Y}}\\;\\phi(\\mathbf{x}, \\mathb...\n",
            "5. inquired about current trends in anticancer drug discovery;\n",
            "selected a target;\n",
            "requested a scaffold ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No relevant docs were retrieved using the relevance score threshold 0.8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "## 3. 유사도 점수 임계값 기반 검색 결과:\n",
            "\n",
            "## 4. 가장 유사한 단일 문서:\n",
            "Memory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\n",
            "\n",
            "Each element is an observation, an event directly provided...\n",
            "\n",
            "## 5. 필터링된 검색 결과:\n",
            "1. Memory stream: is a long-term memory module (external database) that records a comprehensive list of...\n",
            "   Source: https://lilianweng.github.io/posts/2023-06-23-agent/\n",
            "2. LLM Powered Autonomous Agents\n",
            "    \n",
            "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author...\n",
            "   Source: https://lilianweng.github.io/posts/2023-06-23-agent/\n",
            "3. Memory\n",
            "\n",
            "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as ...\n",
            "   Source: https://lilianweng.github.io/posts/2023-06-23-agent/\n",
            "4. Fig. 13. The generative agent architecture. (Image source: Park et al. 2023)\n",
            "This fun simulation res...\n",
            "   Source: https://lilianweng.github.io/posts/2023-06-23-agent/\n"
          ]
        }
      ],
      "source": [
        "# 이전에 생성한 vectorstore를 사용합니다\n",
        "user_query = \"agent memory\"\n",
        "\n",
        "# 1. MMR (Maximal Marginal Relevance) - 다양성 증가\n",
        "mmr_retriever = vectorstore.as_retriever(\n",
        "    search_type=\"mmr\",\n",
        "    search_kwargs={'k': 6, 'lambda_mult': 0.25}\n",
        ")\n",
        "mmr_results = mmr_retriever.invoke(user_query)\n",
        "\n",
        "print(\"## 1. MMR 검색 결과 (다양성 증가):\")\n",
        "for i, doc in enumerate(mmr_results, 1):\n",
        "    print(f\"{i}. {doc.page_content[:100]}...\")\n",
        "\n",
        "# 2. MMR with higher fetch_k\n",
        "mmr_fetch_retriever = vectorstore.as_retriever(\n",
        "    search_type=\"mmr\",\n",
        "    search_kwargs={'k': 5, 'fetch_k': 50}\n",
        ")\n",
        "mmr_fetch_results = mmr_fetch_retriever.invoke(user_query)\n",
        "\n",
        "print(\"\\n## 2. MMR 검색 결과 (높은 fetch_k):\")\n",
        "for i, doc in enumerate(mmr_fetch_results, 1):\n",
        "    print(f\"{i}. {doc.page_content[:100]}...\")\n",
        "\n",
        "# 3. Similarity Score Threshold\n",
        "threshold_retriever = vectorstore.as_retriever(\n",
        "    search_type=\"similarity_score_threshold\",\n",
        "    search_kwargs={'score_threshold': 0.8}\n",
        ")\n",
        "threshold_results = threshold_retriever.invoke(user_query)\n",
        "\n",
        "print(\"\\n## 3. 유사도 점수 임계값 기반 검색 결과:\")\n",
        "for i, doc in enumerate(threshold_results, 1):\n",
        "    print(f\"{i}. {doc.page_content[:100]}...\")\n",
        "\n",
        "# 4. Single Most Similar Document\n",
        "single_retriever = vectorstore.as_retriever(search_kwargs={'k': 1})\n",
        "single_result = single_retriever.invoke(user_query)\n",
        "\n",
        "print(\"\\n## 4. 가장 유사한 단일 문서:\")\n",
        "print(f\"{single_result[0].page_content[:200]}...\")\n",
        "\n",
        "# 5. Filtered Retrieval (주의: 이 예제는 실제 메타데이터에 따라 수정이 필요할 수 있습니다)\n",
        "filtered_retriever = vectorstore.as_retriever(\n",
        "    search_kwargs={'filter': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}}\n",
        ")\n",
        "filtered_results = filtered_retriever.invoke(user_query)\n",
        "\n",
        "print(\"\\n## 5. 필터링된 검색 결과:\")\n",
        "for i, doc in enumerate(filtered_results, 1):\n",
        "    print(f\"{i}. {doc.page_content[:100]}...\")\n",
        "    print(f\"   Source: {doc.metadata.get('source', 'Not available')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXGZf5unq45i"
      },
      "source": [
        "**5. User query와 retrieved chunk 에 대해 relevance 가 있는지를 평가하는 시스템 프롬프트 작성: retrieval 퀄리티를 LLM 이 스스로 평가하도록 하고, 관련이 있으면 {‘relevance’: ‘yes’} 관련이 없으면 {‘relevance’: ‘no’} 라고 출력하도록 함. ( JsonOutputParser() 를 활용 )**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLFY80OE43j3"
      },
      "source": [
        "RAG 용 프롬프트 작성을 위한 Prompt Hub 활용\n",
        "\n",
        "https://smith.langchain.com/hub/rlm/rag-prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "cFsJnLmn44p0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/edward.kk/.pyenv/versions/3.11.9/lib/python3.11/site-packages/langsmith/client.py:333: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain import hub\n",
        "\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnDksZA748kC"
      },
      "source": [
        "output JSON formatting\n",
        "\n",
        "https://python.langchain.com/v0.2/docs/how_to/output_parser_json/#without-pydantic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "jSU4bWjuyIMa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'relevant': 'yes'}\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# JSON 출력 파서 설정\n",
        "parser = JsonOutputParser()\n",
        "\n",
        "# 관련성 체커를 위한 프롬프트 템플릿 정의\n",
        "relevance_prompt = PromptTemplate(\n",
        "    template=\"\"\"당신은 검색 결과의 관련성을 평가하는 전문가입니다. \n",
        "주어진 사용자 쿼리와 검색된 문서 청크의 관련성을 판단해야 합니다.\n",
        "\n",
        "다음 기준을 사용하여 관련성을 평가하세요:\n",
        "1. 문서가 쿼리의 주제나 키워드를 직접적으로 다루고 있는가?\n",
        "2. 문서가 쿼리에 대한 유용한 정보나 통찰을 제공하는가?\n",
        "3. 문서의 내용이 쿼리의 맥락과 일치하는가?\n",
        "\n",
        "관련성이 있다고 판단되면 'yes'를, 없다고 판단되면 'no'를 반환하세요.\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "사용자 쿼리: {query}\n",
        "검색된 문서 청크: {chunk}\n",
        "\n",
        "관련성 평가:\"\"\",\n",
        "    input_variables=[\"query\", \"chunk\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "# LLM 모델 초기화\n",
        "llm = ChatOpenAI(model=\"gpt-4-0125-preview\")\n",
        "\n",
        "# 체인 구성\n",
        "relevance_chain = relevance_prompt | llm | parser\n",
        "\n",
        "# 테스트를 위한 함수 정의\n",
        "def check_relevance(query, chunk):\n",
        "    return relevance_chain.invoke({\"query\": query, \"chunk\": chunk})\n",
        "\n",
        "# 사용 예시\n",
        "if __name__ == \"__main__\":\n",
        "    query = \"agent memory\"\n",
        "    chunk = \"AI agents often require memory to maintain context and improve performance over time. This memory can be short-term for immediate tasks or long-term for retaining important information across multiple interactions.\"\n",
        "    \n",
        "    result = check_relevance(query, chunk)\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVz8Ac07q47_"
      },
      "source": [
        "6. 5 에서 모든 docs에 대해 ‘no’ 라면 디버깅 (Splitter, Chunk size, overlap, embedding model, vector store, retrieval 평가 시스템 프롬프트 등)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:RAG 시스템 디버깅 시작\n",
            "WARNING:__main__:모든 검색된 문서가 관련이 없습니다. 디버깅을 시작합니다.\n",
            "INFO:__main__:현재 Text Splitter 설정: RecursiveCharacterTextSplitter\n",
            "INFO:__main__:Text Splitter 파라미터: 1000, 200\n",
            "INFO:__main__:사용 중인 Embedding 모델: OpenAIEmbeddings\n",
            "INFO:__main__:Vector Store 유형: Chroma\n",
            "INFO:__main__:저장된 총 문서 수: 66\n",
            "INFO:__main__:Retrieval 프로세스 검토 중...\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:__main__:유사 문서 1: Memory stream: is a long-term memory module (external database) that records a comprehensive list of...\n",
            "INFO:__main__:유사 문서 2: They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test s...\n",
            "INFO:__main__:유사 문서 3: }\n",
            "]\n",
            "Then after these clarification, the agent moved into the code writing mode with a different syst...\n",
            "INFO:__main__:유사 문서 4: Memory\n",
            "\n",
            "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as ...\n",
            "INFO:__main__:유사 문서 5: LLM Powered Autonomous Agents\n",
            "    \n",
            "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author...\n",
            "INFO:__main__:개선 제안:\n",
            "INFO:__main__:1. 청크 크기를 조정해 보세요. (예: 현재 크기의 50% 증가 또는 감소)\n",
            "INFO:__main__:2. 오버랩을 조정해 보세요. (예: 현재 오버랩의 2배)\n",
            "INFO:__main__:3. 다른 Embedding 모델을 시도해 보세요. (예: 'text-embedding-3-large')\n",
            "INFO:__main__:4. Vector Store를 재색인화하거나 다른 유형의 Vector Store를 사용해 보세요.\n",
            "INFO:__main__:5. Retrieval 방식을 MMR(Maximum Marginal Relevance)로 변경해 보세요.\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# 로깅 설정\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# 1. 관련성 체커 설정 (이전과 동일)\n",
        "parser = JsonOutputParser()\n",
        "relevance_prompt = PromptTemplate(\n",
        "    template=\"\"\"당신은 검색 결과의 관련성을 평가하는 전문가입니다. \n",
        "주어진 사용자 쿼리와 검색된 문서 청크의 관련성을 판단해야 합니다.\n",
        "{format_instructions}\n",
        "사용자 쿼리: {query}\n",
        "검색된 문서 청크: {chunk}\n",
        "관련성 평가:\"\"\",\n",
        "    input_variables=[\"query\", \"chunk\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4-0125-preview\")\n",
        "relevance_chain = relevance_prompt | llm | parser\n",
        "\n",
        "# 2. 디버깅 함수 정의 (수정됨)\n",
        "def debug_rag_system(query, docs, vectorstore, text_splitter, embeddings):\n",
        "    logger.info(\"RAG 시스템 디버깅 시작\")\n",
        "    \n",
        "    # 2.1 관련성 체크\n",
        "    all_irrelevant = all(\n",
        "        relevance_chain.invoke({\"query\": query, \"chunk\": doc.page_content})[\"relevance\"] == \"no\"\n",
        "        for doc in docs\n",
        "    )\n",
        "    \n",
        "    if not all_irrelevant:\n",
        "        logger.info(\"일부 관련 문서가 검색되었습니다. 추가 디버깅이 필요하지 않습니다.\")\n",
        "        return\n",
        "    \n",
        "    logger.warning(\"모든 검색된 문서가 관련이 없습니다. 디버깅을 시작합니다.\")\n",
        "    \n",
        "    # 2.2 Splitter 및 Chunk size 확인 (수정됨)\n",
        "    logger.info(f\"현재 Text Splitter 설정: {text_splitter.__class__.__name__}\")\n",
        "    logger.info(f\"Text Splitter 파라미터: {text_splitter._chunk_size}, {text_splitter._chunk_overlap}\")\n",
        "    \n",
        "    # 2.3 Embedding 모델 확인\n",
        "    logger.info(f\"사용 중인 Embedding 모델: {embeddings.__class__.__name__}\")\n",
        "    \n",
        "    # 2.4 Vector Store 상태 확인\n",
        "    logger.info(f\"Vector Store 유형: {vectorstore.__class__.__name__}\")\n",
        "    logger.info(f\"저장된 총 문서 수: {vectorstore._collection.count()}\")\n",
        "    \n",
        "    # 2.5 Retrieval 프로세스 검토\n",
        "    logger.info(\"Retrieval 프로세스 검토 중...\")\n",
        "    similar_docs = vectorstore.similarity_search(query, k=5)\n",
        "    for i, doc in enumerate(similar_docs, 1):\n",
        "        logger.info(f\"유사 문서 {i}: {doc.page_content[:100]}...\")\n",
        "    \n",
        "    # 2.6 개선 제안\n",
        "    logger.info(\"개선 제안:\")\n",
        "    logger.info(\"1. 청크 크기를 조정해 보세요. (예: 현재 크기의 50% 증가 또는 감소)\")\n",
        "    logger.info(\"2. 오버랩을 조정해 보세요. (예: 현재 오버랩의 2배)\")\n",
        "    logger.info(\"3. 다른 Embedding 모델을 시도해 보세요. (예: 'text-embedding-3-large')\")\n",
        "    logger.info(\"4. Vector Store를 재색인화하거나 다른 유형의 Vector Store를 사용해 보세요.\")\n",
        "    logger.info(\"5. Retrieval 방식을 MMR(Maximum Marginal Relevance)로 변경해 보세요.\")\n",
        "\n",
        "# 3. 메인 실행 코드\n",
        "if __name__ == \"__main__\":\n",
        "    # 예시 데이터 (실제 환경에서는 이전 단계에서 생성한 객체들을 사용)\n",
        "    query = \"agent memory\"\n",
        "    docs = [\n",
        "        # ... 검색된 문서들 ...\n",
        "    ]\n",
        "    vectorstore = Chroma(embedding_function=OpenAIEmbeddings())\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    \n",
        "    debug_rag_system(query, docs, vectorstore, text_splitter, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIDNNBe9q4-Q"
      },
      "source": [
        "7. 5에서 ‘yes’ 라면 질문과 명확히 관련 없는 docs 나 질문 (예: ‘I like an apple’)에 대해서는 ‘no’ 라고 나오는지 테스트 프롬프트 및 평가 코드 작성. 이 때는 관련 없다는 답변 작성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "테스트 결과 요약:\n",
            "총 테스트 수: 3\n",
            "정확한 테스트 수: 3\n",
            "정확도: 100.00%\n",
            "\n",
            "상세 결과:\n",
            "\n",
            "테스트 케이스 1:\n",
            "쿼리: What is agent memory in AI?\n",
            "청크: Agent memory in AI refers to the ability of AI agents to store and recall information from past expe...\n",
            "예상 결과: yes\n",
            "실제 결과: yes\n",
            "정확성: 정확\n",
            "\n",
            "테스트 케이스 2:\n",
            "쿼리: What is agent memory in AI?\n",
            "청크: The Pacific Ocean is the largest and deepest of Earth's oceanic divisions. It extends from the Arcti...\n",
            "예상 결과: no\n",
            "실제 결과: no\n",
            "정확성: 정확\n",
            "\n",
            "테스트 케이스 3:\n",
            "쿼리: I like an apple\n",
            "청크: Apples are a popular fruit known for their sweet taste and crisp texture. They come in various color...\n",
            "예상 결과: no\n",
            "실제 결과: no\n",
            "정확성: 정확\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "import json\n",
        "\n",
        "# 1. 테스트 케이스 정의\n",
        "test_cases = [\n",
        "    {\n",
        "        \"query\": \"What is agent memory in AI?\",\n",
        "        \"chunk\": \"Agent memory in AI refers to the ability of AI agents to store and recall information from past experiences or interactions. This can include short-term memory for immediate tasks and long-term memory for retaining important information across multiple interactions.\",\n",
        "        \"expected\": \"yes\"\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What is agent memory in AI?\",\n",
        "        \"chunk\": \"The Pacific Ocean is the largest and deepest of Earth's oceanic divisions. It extends from the Arctic Ocean in the north to the Southern Ocean in the south and is bounded by the Americas to the east and Asia and Australia to the west.\",\n",
        "        \"expected\": \"no\"\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"I like an apple\",\n",
        "        \"chunk\": \"Apples are a popular fruit known for their sweet taste and crisp texture. They come in various colors including red, green, and yellow. Apples are rich in fiber and antioxidants, making them a healthy snack choice.\",\n",
        "        \"expected\": \"no\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# 2. 관련성 체커 프롬프트 수정\n",
        "parser = JsonOutputParser()\n",
        "relevance_prompt = PromptTemplate(\n",
        "    template=\"\"\"당신은 검색 결과의 관련성을 평가하는 전문가입니다. \n",
        "주어진 사용자 쿼리와 검색된 문서 청크의 관련성을 판단해야 합니다.\n",
        "\n",
        "다음 기준을 사용하여 관련성을 평가하세요:\n",
        "1. 문서가 쿼리의 주제나 키워드를 직접적으로 다루고 있는가?\n",
        "2. 문서가 쿼리에 대한 유용한 정보나 통찰을 제공하는가?\n",
        "3. 문서의 내용이 쿼리의 맥락과 일치하는가?\n",
        "\n",
        "주의: 쿼리가 명확한 질문이 아니거나 관련성이 낮은 경우(예: \"I like an apple\"), \n",
        "문서와의 관련성을 'no'로 평가하세요.\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "사용자 쿼리: {query}\n",
        "검색된 문서 청크: {chunk}\n",
        "\n",
        "관련성 평가:\"\"\",\n",
        "    input_variables=[\"query\", \"chunk\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4-0125-preview\")\n",
        "relevance_chain = relevance_prompt | llm | parser\n",
        "\n",
        "# 3. 테스트 실행 함수 작성\n",
        "def run_test(test_case):\n",
        "    query = test_case[\"query\"]\n",
        "    chunk = test_case[\"chunk\"]\n",
        "    expected = test_case[\"expected\"]\n",
        "    \n",
        "    result = relevance_chain.invoke({\"query\": query, \"chunk\": chunk})\n",
        "    actual = result[\"relevance\"]\n",
        "    \n",
        "    is_correct = actual == expected\n",
        "    \n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"chunk\": chunk[:100] + \"...\",  # 첫 100자만 표시\n",
        "        \"expected\": expected,\n",
        "        \"actual\": actual,\n",
        "        \"is_correct\": is_correct\n",
        "    }\n",
        "\n",
        "# 4. 결과 평가 및 보고 함수 작성\n",
        "def evaluate_and_report(test_results):\n",
        "    total_tests = len(test_results)\n",
        "    correct_tests = sum(1 for result in test_results if result[\"is_correct\"])\n",
        "    accuracy = correct_tests / total_tests * 100\n",
        "\n",
        "    print(f\"테스트 결과 요약:\")\n",
        "    print(f\"총 테스트 수: {total_tests}\")\n",
        "    print(f\"정확한 테스트 수: {correct_tests}\")\n",
        "    print(f\"정확도: {accuracy:.2f}%\")\n",
        "    \n",
        "    print(\"\\n상세 결과:\")\n",
        "    for i, result in enumerate(test_results, 1):\n",
        "        print(f\"\\n테스트 케이스 {i}:\")\n",
        "        print(f\"쿼리: {result['query']}\")\n",
        "        print(f\"청크: {result['chunk']}\")\n",
        "        print(f\"예상 결과: {result['expected']}\")\n",
        "        print(f\"실제 결과: {result['actual']}\")\n",
        "        print(f\"정확성: {'정확' if result['is_correct'] else '부정확'}\")\n",
        "        \n",
        "        if not result['is_correct']:\n",
        "            print(\"오류 분석:\")\n",
        "            if result['expected'] == 'yes' and result['actual'] == 'no':\n",
        "                print(\"- 관련 있는 내용을 관련 없다고 판단했습니다. 프롬프트의 관련성 기준을 재검토하세요.\")\n",
        "            elif result['expected'] == 'no' and result['actual'] == 'yes':\n",
        "                print(\"- 관련 없는 내용을 관련 있다고 판단했습니다. 프롬프트의 제한 조건을 강화하세요.\")\n",
        "\n",
        "# 5. 메인 실행 코드 작성\n",
        "if __name__ == \"__main__\":\n",
        "    test_results = [run_test(test_case) for test_case in test_cases]\n",
        "    evaluate_and_report(test_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oCGlWIFrBYr"
      },
      "source": [
        "8. ‘yes’ 이고 7의 평가에서도 문제가 없다면, 4의 retrieved chunk 를 가지고 답변 작성\n",
        "prompt | llm | parser 코드 작성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "xGhPcEHK5Swh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "질문: What is agent memory in AI?\n",
            "\n",
            "답변: "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent memory in AI refers to the mechanisms and processes that artificial agents (such as AI models or robots) use to acquire, store, retain, and later retrieve information. This concept mirrors the idea of memory in humans and is crucial for enabling AI systems to perform tasks that require the use of past experiences or knowledge. Agent memory can be broadly categorized into two types:\n",
            "\n",
            "1. **Short-term memory**: This involves the temporary storage of information that an AI model uses for in-context learning and immediate task execution. It's akin to human working memory, where information is briefly held for processing and is essential for understanding and responding to new information.\n",
            "\n",
            "2. **Long-term memory**: This provides AI agents the capability to retain and recall information over extended periods. It often involves leveraging external storage or databases (memory streams) and sophisticated retrieval models to access relevant, important, and recent information. This type of memory allows AI systems to utilize past experiences, learn from them, and apply this knowledge to new situations.\n",
            "\n",
            "Furthermore, agent memory includes mechanisms such as:\n",
            "- **Tool use**: Learning to call external APIs for additional information or capabilities.\n",
            "- **Memory stream**: An external database that records a comprehensive list of the agent's experiences in natural language.\n",
            "- **Retrieval model**: A system that helps surface the most relevant, recent, and important context to inform the agent's behavior.\n",
            "- **Reflection mechanism**: A process that synthesizes memories into higher-level inferences over time, guiding the agent's future behavior.\n",
            "\n",
            "These components work together to enable AI agents to remember, learn from past interactions, and make informed decisions.\n",
            "\n",
            "질문: How does task decomposition work in AI systems?\n",
            "\n",
            "답변: "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task decomposition in AI systems works by breaking down a complex task into smaller, more manageable parts or steps. This process allows an AI to tackle each component of a task sequentially or in parallel, depending on dependencies, making it easier to solve complex problems. There are several approaches to task decomposition:\n",
            "\n",
            "1. **Chain of Thought (CoT)**: Introduced by Wei et al. in 2022, CoT involves instructing the model to \"think step by step\" to break down hard tasks into smaller steps. This technique utilizes additional computation at test-time to enhance performance on complex tasks by transforming them into a series of simpler tasks. The CoT approach not only helps in task decomposition but also provides insights into the model's reasoning process.\n",
            "\n",
            "2. **Tree of Thoughts (ToT)**: Proposed by Yao et al. in 2023, ToT extends CoT by exploring multiple reasoning possibilities at each decomposition step. It first decomposes the problem into several thought steps and then generates multiple thoughts per step, creating a tree structure. This method allows for a more exhaustive search of potential solutions using breadth-first search (BFS) or depth-first search (DFS). Each state can be evaluated through a classifier or by a majority vote, enhancing the model's ability to explore various reasoning paths.\n",
            "\n",
            "3. **Prompting Techniques**: Simple prompting can be used to initiate task decomposition by asking the model to list steps or subgoals for achieving a specific task. This can be done using prompts like \"Steps for XYZ.\\n1.\" or \"What are the subgoals for achieving XYZ?\". Task-specific instructions can also be utilized to guide the model in decomposing tasks, for example, asking for a story outline when writing a novel.\n",
            "\n",
            "4. **Human Inputs**: In some cases, task decomposition may involve direct human inputs, where users can specify tasks, their dependencies, and associated resources. This approach allows for finer control over the decomposition process.\n",
            "\n",
            "The AI system can parse user inputs into structured tasks, identifying dependencies and resources needed for each task. This structured approach enables the AI to plan and execute tasks efficiently, adhering to logical relationships and orderings prescribed by the decomposition process.\n",
            "\n",
            "질문: Can you explain the concept of retrieval-augmented generation?\n",
            "\n",
            "답변: "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieval-augmented generation (RAG) is a concept within the field of artificial intelligence and machine learning, particularly in the development of language models and generative agents. It combines the process of retrieving relevant information from a large dataset or knowledge base with the generative capabilities of models like transformers to produce responses or content that is both relevant and contextually appropriate.\n",
            "\n",
            "In the context of the provided information, this concept can be understood as follows:\n",
            "\n",
            "1. **Retrieval Phase**: The system first retrieves information relevant to a given query or context. This retrieval is akin to looking up information in a vast library (the external vector store) to find the most relevant documents or pieces of information. This step is crucial for the model to access a wide range of information beyond its immediate training data or embedded knowledge, allowing it to pull in specific details or examples that can enhance the quality and relevance of its output.\n",
            "\n",
            "2. **Augmentation Phase**: The retrieved information is then used to augment the generation process. In the case of a language model, this means that the generation of text (or other modalities) is informed by the retrieved information. The model uses this information to construct responses that are not only generated based on its learned patterns and structures but are also specifically tailored to the input query or context with the help of the external information.\n",
            "\n",
            "3. **Generation Phase**: Finally, the model generates the output, integrating the retrieved information into its response. This allows the model to produce outputs that are more accurate, detailed, and contextually relevant than would be possible through generation alone.\n",
            "\n",
            "The concept of RAG is particularly useful in creating intelligent systems that require a deep understanding of context, a wide range of knowledge, and the ability to synthesize information from various sources to generate coherent, relevant, and informed responses or content. This approach enhances the capabilities of language models, making them more powerful tools for tasks such as question answering, content creation, and even complex decision-making processes.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import Document\n",
        "\n",
        "# 1. 필요한 임포트 구성 (위에 포함)\n",
        "\n",
        "# 2. 문서 포맷팅 함수 정의\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# 3. 프롬프트 템플릿 정의\n",
        "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "당신은 지식이 풍부한 AI 어시스턴트입니다. 주어진 컨텍스트를 바탕으로 사용자의 질문에 답변해주세요.\n",
        "답변은 정확하고 간결하게 작성하되, 필요한 경우 자세한 설명을 제공하세요.\n",
        "\n",
        "컨텍스트:\n",
        "{context}\n",
        "\n",
        "사용자 질문: {question}\n",
        "\n",
        "답변:\n",
        "\"\"\")\n",
        "\n",
        "# 4. RAG 체인 구성\n",
        "def create_rag_chain(retriever):\n",
        "    llm = ChatOpenAI(model=\"gpt-4-0125-preview\", streaming=True)\n",
        "    rag_chain = (\n",
        "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "        | prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "    return rag_chain\n",
        "\n",
        "# 5. 답변 생성 및 스트리밍 함수 정의\n",
        "def generate_and_stream_answer(rag_chain, question):\n",
        "    print(f\"질문: {question}\\n\")\n",
        "    print(\"답변: \", end=\"\", flush=True)\n",
        "    for chunk in rag_chain.stream(question):\n",
        "        print(chunk, end=\"\", flush=True)\n",
        "    print(\"\\n\")\n",
        "\n",
        "# 6. 메인 실행 코드\n",
        "if __name__ == \"__main__\":\n",
        "    # 이전 단계에서 생성한 retriever를 사용한다고 가정\n",
        "    from langchain_community.vectorstores import Chroma\n",
        "    from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "    # 예시: Chroma 벡터 스토어와 retriever 설정\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    vectorstore = Chroma(embedding_function=embeddings)\n",
        "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "    rag_chain = create_rag_chain(retriever)\n",
        "\n",
        "    # 테스트 질문\n",
        "    test_questions = [\n",
        "        \"What is agent memory in AI?\",\n",
        "        \"How does task decomposition work in AI systems?\",\n",
        "        \"Can you explain the concept of retrieval-augmented generation?\"\n",
        "    ]\n",
        "\n",
        "    for question in test_questions:\n",
        "        generate_and_stream_answer(rag_chain, question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leyezJ_hrBb2"
      },
      "source": [
        "9. 생성된 답안에 Hallucination 이 있는지 평가하는 시스템 프롬프트 작성. LLM이 스스로 평가하도록 하고, hallucination 이 있으면 {‘hallucination’: ‘yes’} 없으면 {‘hallucination’: ‘no’} 라고 출력하도록 함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "테스트 1 (정확한 답변):\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'hallucination': 'no'}\n",
            "\n",
            "테스트 2 (Hallucination이 포함된 답변):\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'hallucination': 'yes'}\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# 1. Hallucination 체커를 위한 프롬프트 템플릿 정의\n",
        "hallucination_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "당신은 AI가 생성한 답변에서 Hallucination(환각, 잘못된 정보)을 탐지하는 전문가입니다.\n",
        "주어진 컨텍스트와 질문, 그리고 생성된 답변을 비교하여 답변에 Hallucination이 있는지 평가해야 합니다.\n",
        "\n",
        "평가 기준:\n",
        "1. 답변이 제공된 컨텍스트의 정보와 일치하는가?\n",
        "2. 답변이 질문과 관련이 있고 적절한가?\n",
        "3. 답변에 컨텍스트에 없는 추가적인 정보가 포함되어 있는가? 만약 있다면, 그 정보가 일반적으로 알려진 사실인가?\n",
        "4. 답변이 모호하거나 잘못된 정보를 포함하고 있는가?\n",
        "\n",
        "컨텍스트:\n",
        "{context}\n",
        "\n",
        "질문: {question}\n",
        "\n",
        "생성된 답변: {answer}\n",
        "\n",
        "위의 정보를 바탕으로 Hallucination이 있는지 평가하고, 다음 형식으로 결과를 출력하세요:\n",
        "{format_instructions}\n",
        "\n",
        "주의: 'hallucination' 키의 값은 반드시 'yes' 또는 'no'여야 합니다.\n",
        "추가적인 설명이나 이유를 제공하지 마세요.\n",
        "\"\"\")\n",
        "\n",
        "# 2. JSON 출력 파서 설정\n",
        "parser = JsonOutputParser()\n",
        "\n",
        "# 3. Hallucination 체크 체인 구성\n",
        "llm = ChatOpenAI(model=\"gpt-4-0125-preview\")\n",
        "hallucination_chain = hallucination_prompt | llm | parser\n",
        "\n",
        "# 4. Hallucination 체크 함수 정의\n",
        "def check_hallucination(context, question, answer):\n",
        "    result = hallucination_chain.invoke({\n",
        "        \"context\": context,\n",
        "        \"question\": question,\n",
        "        \"answer\": answer,\n",
        "        \"format_instructions\": parser.get_format_instructions()\n",
        "    })\n",
        "    return result\n",
        "\n",
        "# 5. 메인 실행 코드\n",
        "if __name__ == \"__main__\":\n",
        "    # 예시 데이터\n",
        "    context = \"\"\"\n",
        "    AI agents often require memory to maintain context and improve performance over time. \n",
        "    This memory can be short-term for immediate tasks or long-term for retaining important \n",
        "    information across multiple interactions. Agent memory helps in decision making, \n",
        "    learning from past experiences, and providing more coherent and contextually \n",
        "    relevant responses.\n",
        "    \"\"\"\n",
        "    \n",
        "    question = \"What is agent memory in AI?\"\n",
        "    \n",
        "    answer1 = \"\"\"\n",
        "    Agent memory in AI refers to the capability of AI systems to store and recall information \n",
        "    over time. It can be categorized into short-term memory for immediate tasks and long-term \n",
        "    memory for retaining information across multiple interactions. This feature allows AI \n",
        "    agents to make informed decisions, learn from past experiences, and provide more \n",
        "    coherent and contextually relevant responses.\n",
        "    \"\"\"\n",
        "    \n",
        "    answer2 = \"\"\"\n",
        "    Agent memory in AI is a revolutionary technology that allows AI systems to have \n",
        "    emotions and feelings just like humans. It enables AI agents to form deep personal \n",
        "    connections with users and even develop their own personalities over time. This \n",
        "    groundbreaking feature is currently being used in advanced robotics to create \n",
        "    AI companions that can provide emotional support and friendship.\n",
        "    \"\"\"\n",
        "    \n",
        "    print(\"테스트 1 (정확한 답변):\")\n",
        "    result1 = check_hallucination(context, question, answer1)\n",
        "    print(result1)\n",
        "    \n",
        "    print(\"\\n테스트 2 (Hallucination이 포함된 답변):\")\n",
        "    result2 = check_hallucination(context, question, answer2)\n",
        "    print(result2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmO4U-NWrBer"
      },
      "source": [
        "10. 9 에서 ‘yes’ 면 8 로 돌아가서 다시 생성, ‘no’ 면 답변 생성하고 유저에게 답변 생성에 사용된 출처와 함께 출력 (최대 2번까지 다시 생성)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "질문: What is agent memory in AI?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "답변 (생성 시도 횟수: 1):\n",
            "Agent memory in AI refers to the mechanisms and structures that enable an AI agent to store, retain, and retrieve information over time, similar to how human memory functions. It encompasses both short-term and long-term aspects:\n",
            "\n",
            "- **Short-term memory** in AI involves temporary storage that allows the agent to hold and manipulate information relevant to its current task or context. This is akin to human working memory, where the agent utilizes this information for immediate problem-solving or decision-making.\n",
            "\n",
            "- **Long-term memory** provides AI agents with the capability to retain a vast amount of information over extended periods. This can include knowledge learned from past experiences, skills acquired over time, and facts or data that are not immediately necessary but may be relevant in the future. Long-term memory in AI can be enhanced by external databases or memory modules that store comprehensive records of the agent's experiences and interactions.\n",
            "\n",
            "Additionally, AI memory systems may incorporate mechanisms for:\n",
            "- **Retrieval**, to surface relevant information based on the current context, importance of the memory, and its recency.\n",
            "- **Tool use**, where the agent learns to access external APIs or databases to supplement its knowledge or perform specific tasks.\n",
            "- **Reflection**, synthesizing past experiences into higher-level inferences that guide future behavior.\n",
            "\n",
            "These components enable AI agents to perform complex tasks, learn from their experiences, and interact more effectively with their environment or users.\n",
            "\n",
            "사용된 출처:\n",
            "Memory\n",
            "\n",
            "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\n",
            "Long-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\n",
            "\n",
            "\n",
            "Tool use\n",
            "\n",
            "The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\n",
            "\n",
            "Memory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\n",
            "\n",
            "Each element is an observation, an event directly provided by the agent.\n",
            "- Inter-agent communication can trigger new natural language statements.\n",
            "\n",
            "\n",
            "Retrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\n",
            "\n",
            "Recency: recent events have higher scores\n",
            "Importance: distinguish mundane from core memories. Ask LM directly.\n",
            "Relevance: based on how related it is to the current situation / query.\n",
            "\n",
            "\n",
            "Reflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\n",
            "\n",
            "Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\n",
            "Component Two: Memory#\n",
            "(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\n",
            "Types of Memory#\n",
            "Memory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\n",
            "\n",
            "\n",
            "Sensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\n",
            "\n",
            "==================================================\n",
            "\n",
            "질문: How does task decomposition work in AI systems?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "답변 (생성 시도 횟수: 1):\n",
            "Task decomposition in AI systems, particularly in the context of Large Language Models (LLMs) like the one described, works by breaking down complex tasks into smaller, more manageable steps. This process can be understood through two key methodologies:\n",
            "\n",
            "1. **Chain of Thought (CoT):** Introduced by Wei et al. in 2022, CoT involves instructing the model to sequentially break down a task into simpler steps. By \"thinking step by step,\" the model uses additional computation at test time to decompose complex tasks. This approach not only simplifies the task but also provides insight into the model's reasoning process.\n",
            "\n",
            "2. **Tree of Thoughts (ToT):** Building on CoT, the Tree of Thoughts methodology proposed by Yao et al. in 2023, further extends task decomposition by exploring multiple reasoning paths for each step. It begins by breaking the problem into several thought steps and then generates multiple thoughts per step, forming a tree structure. This structure can be navigated using breadth-first search (BFS) or depth-first search (DFS), with decision points evaluated through classifiers or majority votes.\n",
            "\n",
            "Task decomposition can be initiated by:\n",
            "- Simple prompting to an LLM, such as \"Steps for XYZ.\\n1.\" or \"What are the subgoals for achieving XYZ?\"\n",
            "- Employing task-specific instructions, e.g., \"Write a story outline.\" for novel writing tasks.\n",
            "- Incorporating human inputs to guide the decomposition process.\n",
            "\n",
            "In an autonomous agent system, this decomposition allows for detailed planning and execution of tasks. Each subtask can be parsed with specific parameters, including dependencies on previous tasks' outputs, and processed sequentially or in parallel as needed. This structured approach enhances the AI system's ability to manage and execute complex tasks efficiently by treating them as a series of interconnected, simpler tasks.\n",
            "\n",
            "사용된 출처:\n",
            "Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
            "Component One: Planning#\n",
            "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
            "Task Decomposition#\n",
            "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
            "\n",
            "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
            "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
            "\n",
            "The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can't be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\n",
            "\n",
            "==================================================\n",
            "\n",
            "질문: Can you explain the concept of retrieval-augmented generation?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "답변 (생성 시도 횟수: 1):\n",
            "Retrieval-augmented generation (RAG) is a concept in artificial intelligence and natural language processing where a system enhances its generative capabilities by retrieving relevant information from a large corpus or database to inform its output. The process involves two main steps: retrieval and generation.\n",
            "\n",
            "1. **Retrieval**: In this step, the system queries a database or knowledge base to find information relevant to the task at hand. This is achieved by using a query generated from the input (e.g., a question or prompt). The system leverages search algorithms or similarity measures to find and retrieve the most relevant documents or information snippets.\n",
            "\n",
            "2. **Generation**: Once relevant information has been retrieved, the system uses it to generate a response or output. This is typically done using a language model, such as a transformer-based model. The retrieved information is incorporated into the generation process either by directly feeding it into the model as additional context or by blending the information into the model's parameters through techniques like attention mechanisms.\n",
            "\n",
            "The integration of retrieved information with generative models allows for more informed, accurate, and contextually relevant outputs. It effectively combines the strengths of information retrieval systems, which excel at finding specific pieces of information, with the generative capabilities of language models, which are good at producing coherent and fluent text based on given inputs.\n",
            "\n",
            "Retrieval-augmented generation is particularly useful in applications where the generative model needs to produce outputs based on factual information or when the task requires a deep understanding of content that may not be fully captured within the model's training data. Examples include question answering systems, content creation tools, and conversational agents. By leveraging external knowledge sources, RAG systems can offer more precise, detailed, and up-to-date responses than traditional generative models.\n",
            "\n",
            "사용된 출처:\n",
            "Fig. 13. The generative agent architecture. (Image source: Park et al. 2023)\n",
            "This fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\n",
            "Proof-of-Concept Examples#\n",
            "AutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\n",
            "Here is the system message used by AutoGPT, where {{...}} are user inputs:\n",
            "You are {{ai-name}}, {{user-provided AI bot description}}.\n",
            "Your decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\n",
            "\n",
            "GOALS:\n",
            "\n",
            "They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\n",
            "Generative Agents Simulation#\n",
            "Generative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\n",
            "The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\n",
            "\n",
            "Fig. 8. Categorization of human memory.\n",
            "We can roughly consider the following mappings:\n",
            "\n",
            "Sensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\n",
            "Short-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\n",
            "Long-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.\n",
            "\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import Document\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# 1. 필요한 함수들 임포트 (이전 단계에서 정의한 함수들)\n",
        "# format_docs, create_rag_chain, check_hallucination 함수들이 정의되어 있다고 가정\n",
        "\n",
        "# 2. 답변 생성 및 Hallucination 체크 함수 정의\n",
        "def generate_and_check_answer(rag_chain, question, context):\n",
        "    answer = rag_chain.invoke(question)\n",
        "    hallucination_result = check_hallucination(context, question, answer)\n",
        "    return answer, hallucination_result\n",
        "\n",
        "# 3. 전체 RAG 프로세스를 관리하는 함수 정의\n",
        "def rag_process_with_hallucination_check(retriever, question, max_attempts=2):\n",
        "    rag_chain = create_rag_chain(retriever)\n",
        "    context = format_docs(retriever.invoke(question))\n",
        "    \n",
        "    for attempt in range(max_attempts):\n",
        "        answer, hallucination_result = generate_and_check_answer(rag_chain, question, context)\n",
        "        \n",
        "        if hallucination_result['hallucination'] == 'no':\n",
        "            return answer, context, attempt + 1\n",
        "    \n",
        "    # 최대 시도 횟수를 초과한 경우\n",
        "    return answer, context, max_attempts\n",
        "\n",
        "# 4. 메인 실행 코드\n",
        "if __name__ == \"__main__\":\n",
        "    # 벡터 스토어 및 retriever 설정\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    vectorstore = Chroma(embedding_function=embeddings)\n",
        "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "    \n",
        "    # 테스트 질문\n",
        "    test_questions = [\n",
        "        \"What is agent memory in AI?\",\n",
        "        \"How does task decomposition work in AI systems?\",\n",
        "        \"Can you explain the concept of retrieval-augmented generation?\"\n",
        "    ]\n",
        "    \n",
        "    for question in test_questions:\n",
        "        print(f\"\\n질문: {question}\")\n",
        "        \n",
        "        answer, context, attempts = rag_process_with_hallucination_check(retriever, question)\n",
        "        \n",
        "        print(f\"\\n답변 (생성 시도 횟수: {attempts}):\")\n",
        "        print(answer)\n",
        "        \n",
        "        print(\"\\n사용된 출처:\")\n",
        "        print(context)\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-SfRsD_5vYg"
      },
      "source": [
        "11. https://applied-llms.org/ 링크는 llm 을 이용해 1년간 개발해 본 팀이 배운 것들을 정리한 아티클 입니다.\n",
        "\n",
        "저자의 생각을 묻는 질문들에 답하기 위해서\n",
        "\n",
        "1) Chunking & embedding & storing\n",
        "\n",
        "2) Load\n",
        "\n",
        "3) Retrieval\n",
        "\n",
        "4) Generation\n",
        "\n",
        "으로 구성된 RAG 코드를 작성하고 아래 예시 질문에 대한 답을 해보세요.\n",
        "\n",
        "예시)\n",
        "RAG 에 대한 저자의 생각은 무엇인가?\n",
        "RAG 와 fine tuning 에 대해 저자는 어떻게 비교하고 있나?\n",
        "저자가 가장 많은 부분을 할당해 설명하는 개념은 무엇인가?\n",
        "\n",
        "11 실습을 마치지 못했더라도, https://applied-llms.org/ 아티클은 꼼꼼히 정독해보시기를 추천 드립니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "웹 페이지 스크래핑 중...\n",
            "텍스트 청크화 및 임베딩 중...\n",
            "벡터 데이터베이스에 저장 중...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAG 체인 구축 중...\n",
            "\n",
            "질문: RAG에 대한 저자의 생각은 무엇인가?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "답변: 저자는 RAG(Retrieval-Augmented Generation)에 대해 긍정적인 생각을 가지고 있습니다. RAG의 출력 품질이 검색된 문서의 관련성, 밀도, 세부 사항의 질에 달려 있다고 언급하며, 이를 통해 문서 검색의 효율성과 정확성을 높일 수 있다고 설명합니다. 또한, RAG가 지속적인 사전 훈련이나 미세 조정에 비해 유지 관리가 쉽고 비용 효율적이라는 장점을 강조합니다. 문제가 있는 문서를 쉽게 제거하거나 수정할 수 있다는 점, 그리고 다양한 조직에 대해 검색 인덱스를 분할하여 정보의 노출을 방지할 수 있는 세밀한 제어 능력을 RAG의 실질적인 이점으로 보고 있습니다. 마지막으로, 저자는 RAG를 사용하여 관련성 있는 정보를 추출하는 과정에서 불필요한 정보를 제거하는 것의 중요성을 강조하며, 이를 통해 더 효율적이고 정확한 결과를 얻을 수 있다고 믿습니다.\n",
            "\n",
            "질문: RAG와 fine tuning에 대해 저자는 어떻게 비교하고 있나?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "답변: 저자는 RAG와 fine tuning을 비교하면서 RAG를 더 선호하는 입장을 밝히고 있습니다. 연구 결과에 따르면, RAG는 unsupervised finetuning(계속된 사전학습)과 supervised finetuning 모두에 비해 MMLU의 부분집합과 최신 사건들에 대한 평가에서, 훈련 중에 접한 지식뿐만 아니라 완전히 새로운 지식에 대해서도 일관되게 더 나은 성능을 보였습니다. 또한, RAG는 연속적인 사전학습이나 fine tuning에 비해 검색 인덱스를 최신 상태로 유지하는 것이 더 쉽고 저렴하다는 실용적인 이점을 가지고 있습니다. 문제가 있는 문서를 쉽게 제거하거나 수정할 수 있으며, 검색 문서의 세밀한 제어를 가능하게 하여 여러 조직이 자신들만의 인덱스에서 문서를 검색할 수 있도록 하는 등의 이점도 있습니다. 반면에, RAG의 출력 품질은 검색된 문서의 관련성, 밀도, 상세함에 달려 있으며, 이는 MRR이나 NDCG와 같은 순위 메트릭을 통해 측정됩니다. 이러한 점들을 종합해 볼 때, 저자는 RAG가 fine tuning보다 우수한 선택이라고 주장하고 있습니다.\n",
            "\n",
            "질문: 저자가 가장 많은 부분을 할당해 설명하는 개념은 무엇인가?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "답변: 저자가 가장 많은 부분을 할당해 설명하는 개념은 \"Tree of Thoughts (Yao et al. 2023)\"입니다. 이는 CoT를 확장하여 각 단계에서 여러 추론 가능성을 탐색하는 방법으로, 문제를 여러 사고 단계로 분해하고 각 단계마다 여러 생각을 생성하여 트리 구조를 만드는 과정을 설명합니다.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from langchain_community.document_loaders import BSHTMLLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# 1. 웹 페이지 내용 스크래핑\n",
        "def scrape_website(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    return soup.get_text()\n",
        "\n",
        "# 2. 텍스트 청크화 및 임베딩\n",
        "def chunk_and_embed(text):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    chunks = text_splitter.split_text(text)\n",
        "    \n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    return chunks, embeddings\n",
        "\n",
        "# 3. 벡터 데이터베이스 저장\n",
        "def store_in_vectordb(chunks, embeddings):\n",
        "    vectorstore = Chroma.from_texts(chunks, embeddings)\n",
        "    return vectorstore\n",
        "\n",
        "# 4. 검색 및 생성 파이프라인 구축\n",
        "def build_rag_chain(vectorstore):\n",
        "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "    \n",
        "    template = \"\"\"Answer the question based only on the following context:\n",
        "    {context}\n",
        "    \n",
        "    Question: {question}\n",
        "    \n",
        "    Answer:\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_template(template)\n",
        "    \n",
        "    llm = ChatOpenAI(model_name=\"gpt-4-0125-preview\", temperature=0)\n",
        "    \n",
        "    def format_docs(docs):\n",
        "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "    \n",
        "    rag_chain = (\n",
        "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "        | prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "    \n",
        "    return rag_chain\n",
        "\n",
        "# 5. 질문 응답 함수 구현\n",
        "def answer_question(rag_chain, question):\n",
        "    return rag_chain.invoke(question)\n",
        "\n",
        "# 6. 메인 실행 코드\n",
        "if __name__ == \"__main__\":\n",
        "    url = \"https://applied-llms.org/\"\n",
        "    \n",
        "    print(\"웹 페이지 스크래핑 중...\")\n",
        "    text = scrape_website(url)\n",
        "    \n",
        "    print(\"텍스트 청크화 및 임베딩 중...\")\n",
        "    chunks, embeddings = chunk_and_embed(text)\n",
        "    \n",
        "    print(\"벡터 데이터베이스에 저장 중...\")\n",
        "    vectorstore = store_in_vectordb(chunks, embeddings)\n",
        "    \n",
        "    print(\"RAG 체인 구축 중...\")\n",
        "    rag_chain = build_rag_chain(vectorstore)\n",
        "    \n",
        "    questions = [\n",
        "        \"RAG에 대한 저자의 생각은 무엇인가?\",\n",
        "        \"RAG와 fine tuning에 대해 저자는 어떻게 비교하고 있나?\",\n",
        "        \"저자가 가장 많은 부분을 할당해 설명하는 개념은 무엇인가?\"\n",
        "    ]\n",
        "    \n",
        "    for question in questions:\n",
        "        print(f\"\\n질문: {question}\")\n",
        "        answer = answer_question(rag_chain, question)\n",
        "        print(f\"답변: {answer}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
